{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composability\n",
    "\n",
    "`bodhilib` library is designed with composability in mind. It takes many ideas from strict functional languages like `Haskell` to design and implement its interface.\n",
    "\n",
    "Using the bodhilib library, you can simplify the ingestion phase of your RAG process as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "1. Ensure bodhilib is installed, along with LLM plugin (`bodhiext.openai`), Embedder plugin (`bodhiext.sentence_transformers`), VectorDB plugin (`bodhiext.qdrant`).\n",
    "1. Ensure `fn.py` is installed for the functional composition methods.\n",
    "1. Ensure OPENAI_API_KEY is set in environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bodhilib bodhiext.openai bodhiext.sentence_transformers bodhiext.qdrant fn.py python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the components\n",
    "from bodhilib import get_llm, get_data_loader, get_embedder, get_vector_db, get_splitter\n",
    "\n",
    "data_loader = get_data_loader(\"file\")\n",
    "splitter = get_splitter(\"text_splitter\")\n",
    "embedder = get_embedder(\"sentence_transformers\")\n",
    "vector_db = get_vector_db(\"qdrant\", location=\":memory:\")\n",
    "llm = get_llm(\"openai_chat\", model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.delete_collection(\"test\")\n",
    "vector_db.create_collection(\"test\", dimension=embedder.dimension, distance=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_db.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fn import F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader.add_resource(dir=\"../data\", recursive=True)\n",
    "\n",
    "f = (\n",
    "    F(data_loader.load)\n",
    "    >> F(splitter.split)\n",
    "    >> F(embedder.embed)\n",
    "    >> F(lambda nodes: vector_db.upsert(collection_name=\"test\", nodes=nodes))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = f()\n",
    "len(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to query your VectorDB, you can compose it like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bodhilib import PromptTemplate\n",
    "\n",
    "template = \"\"\"Below are the text chunks from a blog/article. \n",
    "1. Read and understand the text chunks\n",
    "2. After the text chunks, there are list of questions starting with `Question:`\n",
    "3. Answer the questions from the information given in the text chunks\n",
    "4. If you don't find the answer in the provided text chunks, say 'I couldn't find the answer to this question in the given text'\n",
    "\n",
    "{% for text in texts %}\n",
    "### START\n",
    "{{ text }}\n",
    "### END\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ query }}\n",
    "Answer: \n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(template=template, format='jinja2')\n",
    "\n",
    "input_query = \"According to Paul Graham, how to tackle when you are in doubt?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Paul Graham, when you are in doubt about what to work on, you should optimize for\n",
      "interestingness. He suggests trying lots of things, meeting lots of people, reading lots of books,\n",
      "and asking lots of questions.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "answer = (\n",
    "    F(embedder.embed)\n",
    "    >> F(\n",
    "        lambda e: vector_db.query(\n",
    "            collection_name=\"test\", embedding=e[0].embedding, limit=5\n",
    "        )\n",
    "    )\n",
    "    >> F(lambda nodes: prompt_template.to_prompts(query=input_query, texts = [node.text for node in nodes]))\n",
    "    >> F(llm.generate)\n",
    ")\n",
    "\n",
    "response = answer(input_query)\n",
    "\n",
    "print(textwrap.fill(response.text, width=100, replace_whitespace=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bodhi-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
