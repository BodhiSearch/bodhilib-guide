{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Components\n",
    "\n",
    "The core components of bodhilib are -\n",
    "\n",
    "1. [DataLoader](#dataloader)\n",
    "1. [Splitter](#splitter)\n",
    "1. [Embedder](#embedder)\n",
    "1. [PromptSource](#promptsource)\n",
    "1. [VectorDB](#vectordb)\n",
    "1. [LLM](#llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n",
    "\n",
    "DataLoader is used to load documents from various sources. These sources can be local file, or a URL, or a database.\n",
    "\n",
    "A DataLoader is configured using the `add_resource` method. Once configured, it can be either iterated to fetch the resources as `Document` on-demand, or eager fetched using the `load` method to get it as a `List[Document]`.\n",
    "\n",
    "\n",
    "### class DataLoader\n",
    "```python\n",
    "class DataLoader(Iterable[Document], abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def add_resource(self, **kwargs: Dict[str, Any]) -> None: ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def __iter__(self) -> Iterator[Document]: ...\n",
    "\n",
    "    def load(self) -> List[Document]: ...\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitter\n",
    "\n",
    "Splitter is used to split `Document` into right-sized processible chunks. For flexibility and composability, it takes in `SerializedInput`, and returns a list of `Node` with text corresponding to splits done by the implementation.\n",
    "\n",
    "Ideally, you pass in `Document` or a list of `Document` to get back a list of `Node` split into processible chunks.\n",
    "\n",
    "### class Splitter\n",
    "```python\n",
    "class Splitter(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def split(self, inputs: SerializedInput) -> List[Node]: ...\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedder\n",
    "\n",
    "Embedder embeds a text and returns a vector representation of the given text.\n",
    "\n",
    "Ideally, Embedder takes in `Node` or list of `Node`, and returns the Node enriched with embedding by populating the `embedding` field of the Node.\n",
    "\n",
    "```python\n",
    "class Embedder(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def embed(self, inputs: SerializedInput) -> List[Node]: ...\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PromptSource\n",
    "\n",
    "`PromptSource` provides you an interface to browse and search through collection of most effective prompts. This way, you can test multiple prompt templates for your use-case and find the one that works for you.\n",
    "\n",
    "### class PromptSource\n",
    "```python\n",
    "class PromptSource(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def find(self, keywords: str | List[str]) -> List[PromptTemplate]: ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def list_all(self) -> List[PromptTemplate]: ...\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorDB\n",
    "\n",
    "VectorDB defines the interface to interact with various Vector Databases. VectorDB has two main interface - `upsert` and `query`.\n",
    "\n",
    "`upsert` takes in a list of `Node`, and inserts or update the underlying VectorDB with the `text`, `metadata` and the `embedding` in  the `Node` object. These can later be used to query based on property or vector search.\n",
    "\n",
    "`query` method allows you to query the underlying vector database with the given embedding and property filters. The property filters uses the `MongoDB` query syntax, and not tied to specific vector database. These property filters are transformed by the `VectorDB` to the database specific filters.\n",
    "\n",
    "### class VectorDB\n",
    "\n",
    "```python\n",
    "class VectorDB(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def upsert(self, collection_name: str, nodes: List[Node]) -> List[Node]: ...\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def query(\n",
    "        self, collection_name: str, embedding: Embedding, filter: Optional[Dict[str, Any]], **kwargs: Dict[str, Any]\n",
    "    ) -> List[Node]: ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM\n",
    "\n",
    "LLM defines the interface to interact with a Large Language Model.\n",
    "\n",
    "The `generate` method takes in a flexible input type `SerializedInput` and returns a response generated by the LLM.\n",
    "\n",
    "### class LLM\n",
    "```python\n",
    "class LLM(abc.ABC):\n",
    "    @abc.abstractmethod\n",
    "    def generate(\n",
    "        self,\n",
    "        prompt_input: SerializedInput,\n",
    "        *,\n",
    "        stream: Optional[bool] = None,\n",
    "        **kwargs: Dict[str, Any]) -> Union[Prompt, PromptStream]: ...\n",
    "```\n",
    "\n",
    "### LLM flexible input types\n",
    "\n",
    "LLM takes in `SerializedInput`. So any of the calls below are valid -\n",
    "```python\n",
    "llm.generate(\"tell me a joke\")\n",
    "llm.generate([\"tell me a joke\", \"joke should be related to architects\"])\n",
    "llm.generate(Prompt(\"tell me a joke\"))\n",
    "llm.generate([Prompt(\"you are a helpful AI assistant.\", role=\"system\"), Prompt(\"tell me a joke\")])\n",
    "llm.generate({\"text\": \"tell me a joke\", \"role\": \"user\"})\n",
    "llm.generate([{\"text\": \"you are a helpful AI assistant.\", \"role\": \"system\"}, {\"text\": \"tell me a joke\", \"role\": \"user\"}])\n",
    "```\n",
    "\n",
    "### LLM asynchronous PromptStream\n",
    "\n",
    "LLM `generate` method returns a `Prompt` object, which is a synchronous response from the LLM. \n",
    "\n",
    "If you pass `stream=True`, then the LLM generate method returns `PromptStream` that is a asynchronous response model, and gives you ability to asynchronously receive and process the response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ðŸŽ‰ We just got familiar with the components of bodhilib.\n",
    "\n",
    "Next, letâ€™s see the functional paradigms that guided the design of bodhilib, and how it helps with [Composability](Composability.ipynb)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
