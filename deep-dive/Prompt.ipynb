{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide we are going to explore the following models -\n",
    "\n",
    "1. Prompt\n",
    "1. Role\n",
    "1. Source\n",
    "1. PromptStream\n",
    "\n",
    "Prompt is the most fundamental object in bodhilib library. It is used both to pass as input to the LLM service, as well as returned as response from the LLM service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt encapsulating input/output schema to interact with LLM service.\n"
     ]
    }
   ],
   "source": [
    "# All the classes and methods are imported from the top-level package bodhilib. \n",
    "# Let's import Prompt class from bodhilib.\n",
    "from bodhilib import Prompt\n",
    "\n",
    "# Let's see what all attributes and methods are supported by Prompt class.\n",
    "print(Prompt.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "The `Prompt` class contains 3 fields, these are (with their types) - \n",
    "\n",
    "1. text: str\n",
    "\n",
    "    text is the main content of the Prompt class. It contains the input that the user provides to be sent to the LLM service.\n",
    "\n",
    "1. role: Role\n",
    "\n",
    "    The possible values for role are 'system', 'ai' and 'user'. It indicates the persona of who is providing the input. \n",
    "    \n",
    "    As role='system', you can guide the LLM to generate response in a particular format, or from a particular point of view. This helps keeping the response within a strict boundaries.\n",
    "\n",
    "    As role='ai', indicates that this prompt was generated by the LLM as a response. This is helpful when we are having a chat with LLM, and need to pass in the history of conversation for the next response.\n",
    "\n",
    "    As role='user', indicates that this prompt is provided by the user. This helps the LLM to generate a response for this particular input.\n",
    "\n",
    "1. source: Source\n",
    "\n",
    "    The possible values for source are 'input' and 'output'. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bodhi-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
