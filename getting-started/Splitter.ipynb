{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitter\n",
    "\n",
    "In the previous guide on [DataLoader](DataLoader), we learned how to load documents. Some of these documents could be quite large, making them not processible for LLM operations, such as Embedding etc.\n",
    "\n",
    "To split these documents into processible chunks, we use `Splitter`, and split the `Document` into a list of processible entities as a `Node` object.\n",
    "\n",
    "First, we get an instance of `Splitter` and configure it to fits our use case, then we use the `split` method passing list of `Document` and get list of `Node`. These nodes have `text` content which is based on our desired configuration.\n",
    "\n",
    "For example, we will use the Paul Graham's essays loaded in the previous [DataLoader](DataLoader) guide, and split it using `sentence-splitter`, and get list of `Node` with desired length of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Paul Graham essays from data/data-loader directory using `file` DataLoader\n",
    "import os\n",
    "from pathlib import Path\n",
    "from bodhilib import get_data_loader\n",
    "\n",
    "# Get data directory path and add it to data_loader\n",
    "current_dir = current_working_directory = Path(os.getcwd())\n",
    "data_dir = current_dir / \"..\" / \"data\" / \"data-loader\"\n",
    "data_loader = get_data_loader('file')\n",
    "data_loader.add_resource(dir=str(data_dir))\n",
    "docs = data_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get instance of sentence splitter\n",
    "# Configure sentence splitter to split documents for max length of 300 words, with overlap of 30 words between splits\n",
    "\n",
    "from bodhilib import get_splitter\n",
    "\n",
    "splitter = get_splitter(\"text_splitter\", max_len=300, overlap=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the documents using splitter\n",
    "\n",
    "nodes = splitter.split(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes: 47\n",
      "Content of first node:\n",
      "          How to Get New Ideas  January 2023  (Someone fed my essays into GPT to make something that\n",
      "could answer questions based on them, then asked it where good ideas come from. The answer was ok,\n",
      "but not what I would have said. This is what I would have said.)  The way to get new ideas is to\n",
      "notice anomalies: what seems strange, or missing, or broken? You can see anomalies in everyday life\n",
      "(much of standup comedy is based on this), but the best place to look for them is at the frontiers\n",
      "of knowledge.  Knowledge grows fractally. From a distance its edges look smooth, but when you learn\n",
      "enough to get close to one, you'll notice it's full of gaps. These gaps will seem obvious; it will\n",
      "seem inexplicable that no one has tried x or wondered about y. In the best case, exploring such gaps\n",
      "yields whole new fractal buds.\n",
      "---\n",
      "Content of last node:\n",
      "and engage directly with their audience is probably a good idea.  [29] It may be helpful always to\n",
      "walk or run the same route, because that frees attention for thinking. It feels that way to me, and\n",
      "there is some historical evidence for it.    Thanks to Trevor Blackwell, Daniel Gackle, Pam Graham,\n",
      "Tom Howard, Patrick Hsu, Steve Huffman, Jessica Livingston, Henry Lloyd-Baker, Bob Metcalfe, Ben\n",
      "Miller, Robert Morris, Michael Nielsen, Courtenay Pipkin, Joris Poort, Mieke Roos, Rajat Suri, Harj\n",
      "Taggar, Garry Tan, and my younger son for suggestions and for reading drafts.\n"
     ]
    }
   ],
   "source": [
    "# analyze the nodes\n",
    "import textwrap\n",
    "\n",
    "print(\"Total number of nodes:\", len(nodes))\n",
    "print(\"Content of first node:\")\n",
    "print(textwrap.fill(nodes[0].text, 100))\n",
    "print(\"---\")\n",
    "print(\"Content of last node:\")\n",
    "print(textwrap.fill(nodes[-1].text, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ðŸŽ‰ We just split the Document into Nodes, and can now process it for our LLM use-cases.\n",
    "\n",
    "Next, letâ€™s see how we can embed these nodes using [Embedder](Embedder.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bodhilib-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
