{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt\n",
    "\n",
    "In this Getting Started guide on Prompt and related models, we are going to quickly skim through -\n",
    "\n",
    "1. What is a Prompt?\n",
    "1. Components of a Prompt\n",
    "1. How to build a Prompt\n",
    "\n",
    "We will not deep-dive into the Prompt here. If you are interested in learning more, you can check out the detailed guide on Prompt in the [deep-dive](/deep-dive/) section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Ensure bodhilib is installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install bodhilib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Prompt?\n",
    "\n",
    "A 'Prompt' serves as the input for the Language Models (LLM) service, directing it to generate a response. In addition to this, the LLM service also returns a 'Prompt' as a response.\n",
    "\n",
    "## Components of a Prompt?\n",
    "\n",
    "Prompt consists of `text`, `role` and `source`. \n",
    "\n",
    "- `text` is the core content of the 'Prompt'. It represents the query asked to the LLM service. In the case of a response, it holds the text provided by the LLM service.\n",
    "- `role` can be `system`, `ai` and `user`. It identifies the author or persona of the Prompt.\n",
    "- `source` can be `input` and `output`. This indicates if it is an input to the LLM service, or an output from it.\n",
    "\n",
    "For more details on the components of a Prompt, refer to the [deep-dive](/deep-dive/) section.\n",
    "\n",
    "## How to Build a Prompt?\n",
    "\n",
    "Building a Prompt is as simple as passing a string to the constructor. By default, the `role` is set to â€˜userâ€™ and `source` to â€˜inputâ€™."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> text='What day comes after Monday?' role=<Role.USER: 'user'> source=<Source.INPUT: 'input'>\n"
     ]
    }
   ],
   "source": [
    "# import the Prompt object from `bodhilib` library\n",
    "from bodhilib import Prompt\n",
    "\n",
    "prompt = Prompt(\"What day comes after Monday?\")\n",
    "print(\">\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Prompt uses [Pydantic v1](https://docs.pydantic.dev/1.10/) to provide the Model methods utility. So you can construct Prompt in different ways that Pydantic supports. For e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> text='Using the exploded keyword arguments?' role=<Role.USER: 'user'> source=<Source.INPUT: 'input'>\n"
     ]
    }
   ],
   "source": [
    "# Using exploded keyword arguments\n",
    "\n",
    "prompt = Prompt(**{\"text\": \"Using the exploded keyword arguments?\", \"role\": \"user\", \"source\": \"input\"})\n",
    "print(\">\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> text='Using the python objects' role=<Role.USER: 'user'> source=<Source.INPUT: 'input'>\n"
     ]
    }
   ],
   "source": [
    "# Using python object for Role and Source\n",
    "# Let's first import them from the package\n",
    "from bodhilib import Role, Source\n",
    "\n",
    "# And use it to construct the Prompt\n",
    "prompt = Prompt(text=\"Using the python objects\", role=Role.USER, source=Source.INPUT)\n",
    "print(\">\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ðŸŽ‰ We just created our Prompt model.\n",
    "\n",
    "Next, let's see how to generate a response from [LLM](LLM.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bodhi-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
