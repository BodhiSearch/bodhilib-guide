{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "\n",
    "DataLoader component allows you to load data from various data sources using a uniform interface.\n",
    "\n",
    "To use the DataLoader service, get the instance of data loader using the `get_data_loader` method, passing it the service identifier `service_name`.\n",
    "\n",
    "To configure the `DataLoader`, you can use the `add_resource` method. To start loading the data lazily as python generator, you can iterate over the dataloader using the `for` loop, or if you want to eagerly load all the data synchronously, you can use the `load` method and return the loaded data as list. The `DataLoader.load` method reads the config to load the resource and returns it as list of `Document` object.\n",
    "\n",
    "Let's load local files as data and see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 144\n",
      "-rw-r--r--  1 user36  staff  67153 Sep 29 12:52 pg-great-work.txt\n",
      "-rw-r--r--  1 user36  staff    821 Sep 29 12:52 pg-new-ideas.txt\n"
     ]
    }
   ],
   "source": [
    "# Local data\n",
    "# We have few essays by Paul Graham to load and test out DataLoader component\n",
    "! ls -l ../data/data-loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an instance of local file DataLoader\n",
    "from bodhilib import get_data_loader\n",
    "\n",
    "data_loader = get_data_loader('file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get data directory path and add it to data_loader\n",
    "current_dir = current_working_directory = Path(os.getcwd())\n",
    "data_dir = current_dir / \"..\" / \"data\" / \"data-loader\"\n",
    "data_loader.add_resource(dir=str(data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "docs = data_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2\n",
      "List of filenames loaded: [\n",
      "  {\n",
      "    \"filename\": \"pg-new-ideas.txt\"\n",
      "  },\n",
      "  {\n",
      "    \"filename\": \"pg-great-work.txt\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# analyze the loaded documents\n",
    "import json\n",
    "\n",
    "print(\"Number of documents:\", len(docs))\n",
    "print(\"List of filenames loaded:\", json.dumps([{'filename': doc.metadata['filename']} for doc in docs], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "ðŸŽ‰ We just loaded documents from local using our DataLoader.\n",
    "\n",
    "Next, letâ€™s see how we can split these document into processible entities using [Splitter](Splitter.ipynb).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bodhilib-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
