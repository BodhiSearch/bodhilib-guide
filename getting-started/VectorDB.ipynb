{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VectorDB\n",
    "\n",
    "VectorDB interface allows to insert vector embeddings into a Vector Database. These records can then later be queried for nearest neighbour search, and return back similar records found in the database.\n",
    "\n",
    "To insert and query the records, we have to do the following -\n",
    "\n",
    "1. Create embeddings for our nodes\n",
    "1. Insert the embeddings along with node metadata into the vector database\n",
    "1. Take an input query and embed it into a vector embedding\n",
    "1. Query the VectorDB with input embedding and get similar node back from VectorDB\n",
    "\n",
    "We have already covered task #1 on how to convert a Node into an embedding in the [Embedder](Embedder) guide. In this guide we are going to try out task #2, #3, and #4.\n",
    "\n",
    "For this we need to:\n",
    "\n",
    "1. Prepare our Node embeddings as we did in the [Embedder](Embedder) guide\n",
    "1. Get an instance of VectorDB using the `get_vector_db` method, along with its configuration\n",
    "1. Insert our nodes into the vector database using the `upsert` method\n",
    "1. Embed an input query using the same [Embedder](Embedder)\n",
    "1. Query the VectorDB using the `query` method\n",
    "\n",
    "For this Getting Started guide, we are going to use Qdrant in-memory vector database. Let's get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the qdrant dependencies are installed\n",
    "!pip install -q qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure the bodhiext.qdrant plugin is installed\n",
    "# !pip install -q bodhiext.qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the node embeddings for the Paul Graham's essay:\n",
    "# 1. Load the Paul Graham essays from data/data-loader directory using `file` DataLoader\n",
    "# 2. Convert it into Nodes using sentence_splitter\n",
    "# 3. Enrich node embeddings using the sentence_transformers\n",
    "import os\n",
    "from pathlib import Path\n",
    "from bodhilib import get_data_loader, get_splitter, get_embedder\n",
    "\n",
    "# Get data directory path and add it to data_loader\n",
    "current_dir = current_working_directory = Path(os.getcwd())\n",
    "data_dir = current_dir / \"..\" / \"data\" / \"data-loader\"\n",
    "data_loader = get_data_loader('file')\n",
    "data_loader.add_resource(dir=str(data_dir))\n",
    "docs = data_loader.load()\n",
    "splitter = get_splitter(\"text_splitter\", max_len=300, overlap=30)\n",
    "nodes = splitter.split(docs)\n",
    "embedder = get_embedder(\"sentence_transformers\")\n",
    "_ = embedder.embed(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an instance of Vector DB\n",
    "from bodhilib import get_vector_db\n",
    "\n",
    "vector_db = get_vector_db(\"qdrant\", location=\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bodhilib import Distance\n",
    "\n",
    "collection_name = \"test_collection\"\n",
    "if \"test_collection\" in vector_db.get_collections():\n",
    "    vector_db.delete_collection(\"test_collection\")\n",
    "vector_db.create_collection(collection_name=collection_name, dimension=embedder.dimension, distance=Distance.COSINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert the Node embeddings and return database enriched Node object\n",
    "\n",
    "_ = vector_db.upsert(collection_name, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db49994d-3fc2-4c02-bf12-00319f212339\n"
     ]
    }
   ],
   "source": [
    "# the nodes object has been enriched with database record identifier `id`\n",
    "print(nodes[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the input query using Embedder\n",
    "input_query = \"According to Paul Graham, how to tackle when you are in doubt?\"\n",
    "embedding = embedder.embed(input_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the vector db using the input embedding\n",
    "result = vector_db.query(collection_name, embedding[0].embedding, limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who sits back and offers sophisticated-sounding criticisms of them. \"It's easy to criticize\" is true\n",
      "in the most literal sense, and the route to great work is never easy.  There may be some jobs where\n",
      "it's an advantage to be cynical and pessimistic, but if you want to do great work it's an advantage\n",
      "to be optimistic, even though that means you'll risk looking like a fool sometimes. There's an old\n",
      "tradition of doing the opposite. The Old Testament says it's better to keep quiet lest you look like\n",
      "a fool. But that's advice for seeming smart. If you actually want to discover new things, it's\n",
      "better to take the risk of telling people your ideas.  Some people are naturally earnest, and with\n",
      "others it takes a conscious effort. Either kind of earnestness will suffice. But I doubt it would be\n",
      "possible to do great work without being earnest. It's so hard to do even if you are. You don't have\n",
      "enough margin for error to accommodate the distortions introduced by being affected, intellectually\n",
      "dishonest, orthodox, fashionable, or cool. [14]      Great work is consistent not only with who did\n",
      "it, but with itself. It's usually all of a piece. So if you face a decision in the middle of working\n",
      "on something, ask which choice is more consistent.  You may have to throw things away and redo them.\n",
      "You won't necessarily have to, but you have to be willing to. And that can take some effort; when\n",
      "there's something you need to redo, status quo bias and laziness will combine to keep you in denial\n",
      "about it. To beat this ask: If I'd already made the change, would I want to revert to what I have\n",
      "now?  Have the confidence to cut.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "print(textwrap.fill(result[0].text, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "ðŸŽ‰ We just inserted and queried our document using VectorDB.\n",
    "\n",
    "Finally, letâ€™s see how we can use LLM to do extractive Q&A and give us direct result from the selected records."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bodhilib-guide",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
